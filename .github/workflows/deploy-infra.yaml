name: deploy infra

on:
  push:
    branches:
      - main
      - develop
    paths:
      - "infra/cfn/networking.yaml"
      - "infra/cfn/eks.yaml"
      - "infra/cfn/karpenter.yaml"
      - ".github/workflows/deploy-infra.yaml"
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  set-env:
    runs-on: ubuntu-latest
    outputs:
      env: ${{ steps.set-env.outputs.env }}
    steps:
      - name: Determine environment
        id: set-env
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "env=production" >> $GITHUB_OUTPUT
          else
            echo "env=development" >> $GITHUB_OUTPUT
          fi
  deploy:
    needs: set-env
    runs-on: ubuntu-latest
    environment: ${{ needs.set-env.outputs.env }}

    env:
      AWS_REGION: ap-southeast-2
      APP_NAME: roommate
      NETWORKING_STACK_NAME: roommate-networking-${{ vars.ENV_SHORTHAND }}
      EKS_STACK_NAME: roommate-eks-${{ vars.ENV_SHORTHAND }}
      KARPENTER_STACK_NAME: roommate-karpenter-${{ vars.ENV_SHORTHAND }}
      LB_CONTROLLER_VERSION: "2.9.0"

    steps:
      - name: deploy networking cfn
        run: echo ${{ needs.set-env.outputs.env }}

      - name: checkout
        uses: actions/checkout@v4

      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE }}
          aws-region: ${{ env.AWS_REGION }}

      - name: install eksctl
        run: |
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz"
          tar -xzf eksctl_Linux_amd64.tar.gz
          sudo mv eksctl /usr/local/bin

      - name: deploy networking cfn
        run: |
          aws cloudformation deploy \
            --stack-name "${NETWORKING_STACK_NAME}" \
            --template-file infra/cfn/networking.yaml \
            --region "${AWS_REGION}" \
            --no-fail-on-empty-changeset \
            --parameter-overrides \
              Env="${{ vars.ENV_SHORTHAND }}" \
              VpcCidr="${{ vars.VPC_CIDR }}"

      - name: deploy eks cfn
        run: |
          aws cloudformation deploy \
            --stack-name "${EKS_STACK_NAME}" \
            --template-file infra/cfn/eks.yaml \
            --region "${AWS_REGION}" \
            --no-fail-on-empty-changeset \
            --capabilities CAPABILITY_NAMED_IAM \
            --parameter-overrides \
            Env="${{ vars.ENV_SHORTHAND }}" \
            NetworkStackName="${NETWORKING_STACK_NAME}" \
            NodeInstanceType="${{ vars.NODE_INSTANCE_TYPE }}" \
            NodeDesiredSize="${{ vars.NODE_DESIRED_SIZE }}" \
            NodeMinSize="${{ vars.NODE_MIN_SIZE }}" \
            NodeMaxSize="${{ vars.NODE_MAX_SIZE }}" \
            DomainName="${{ vars.DOMAIN_NAME }}" \
            HostedZoneId="${{ vars.HOSTED_ZONE_ID }}"
      
      - name: deploy karpenter cfn
        run: |
          aws cloudformation deploy \
            --stack-name "${KARPENTER_STACK_NAME}" \
            --template-file infra/cfn/karpenter.yaml \
            --region "${AWS_REGION}" \
            --no-fail-on-empty-changeset \
            --capabilities CAPABILITY_NAMED_IAM \
            --parameter-overrides \
            Env="${{ vars.ENV_SHORTHAND }}" \
            NetworkStackName="${NETWORKING_STACK_NAME}" \
            EksStackName="${EKS_STACK_NAME}"
      
      - name: get helm inputs
        run: |
          echo "getting cluster name..."
          CLUSTER_NAME=$(aws cloudformation describe-stacks \
          --stack-name ${EKS_STACK_NAME} \
          --query "Stacks[0].Outputs[?OutputKey=='ClusterName'].OutputValue" \
          --output text)
          echo "cluster name: '$CLUSTER_NAME'"
          echo "CLUSTER_NAME=$CLUSTER_NAME" >> $GITHUB_ENV

          echo "getting karpenter controller role arn..."
          CONTROLLER_ROLE_ARN=$(aws cloudformation describe-stacks \
          --stack-name ${KARPENTER_STACK_NAME} \
          --query "Stacks[0].Outputs[?OutputKey=='KarpenterControllerRoleArn'].OutputValue" \
          --output text)
          echo "karpenter controller role arn: '$CONTROLLER_ROLE_ARN'"
          echo "CONTROLLER_ROLE_ARN=$CONTROLLER_ROLE_ARN" >> $GITHUB_ENV

          echo "getting node role arn..."
          NODE_ROLE=$(aws cloudformation describe-stacks \
          --stack-name ${KARPENTER_STACK_NAME} \
          --query "Stacks[0].Outputs[?OutputKey=='KarpenterNodeRoleArn'].OutputValue" \
          --output text)
          echo "node role arn: '$NODE_ROLE'"
          echo "NODE_ROLE=$NODE_ROLE" >> $GITHUB_ENV

          echo "getting node role name..."
          NODE_ROLE_NAME="${NODE_ROLE##*/}"
          echo "node role name: '$NODE_ROLE_NAME'"
          echo "NODE_ROLE_NAME=$NODE_ROLE_NAME" >> $GITHUB_ENV

          echo "getting vpc id..."
          VPC_ID=$(aws cloudformation describe-stacks \
          --stack-name ${NETWORKING_STACK_NAME} \
          --query "Stacks[0].Outputs[?OutputKey=='VpcId'].OutputValue" \
          --output text)
          echo "vpc id: '$VPC_ID'"
          echo "VPC_ID=$VPC_ID" >> $GITHUB_ENV

          echo "getting ingress certificate arn..."
          CERTIFICATE_ARN=$(aws cloudformation describe-stacks \
          --stack-name ${EKS_STACK_NAME} \
          --query "Stacks[0].Outputs[?OutputKey=='CertificateArn'].OutputValue" \
          --output text)
          echo "ingress certificate arn: '$CERTIFICATE_ARN'"
          echo "CERTIFICATE_ARN=$CERTIFICATE_ARN" >> $GITHUB_ENV

      - name: deploy karpenter controller
        run: |
          echo "configuring kubectl connection to cluster..."
          aws eks update-kubeconfig --name $CLUSTER_NAME --region ${AWS_REGION}

          echo "executing karpenter controller helm..."
          helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
            --version "1.0.0" \
            --namespace karpenter \
            --create-namespace \
            --set "settings.clusterName=$CLUSTER_NAME" \
            --set "settings.interruptionQueue=$CLUSTER_NAME" \
            --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=$CONTROLLER_ROLE_ARN \
            --set replicas=${{ vars.NODE_DESIRED_SIZE }}
      
      - name: deploy karpenter nodepool
        run: |
          echo "creating node role identity mapping..."
          eksctl create iamidentitymapping \
            --cluster "$CLUSTER_NAME" \
            --arn "$NODE_ROLE" \
            --username "system:node:{{EC2PrivateDNSName}}" \
            --group "system:bootstrappers" \
            --group "system:nodes" \
            --region "${{ env.AWS_REGION }}"

          echo "executing karpenter nodepool helm..."
          helm upgrade --install karpenter-nodepool ./infra/helm/karpenter \
            -f ./infra/helm/karpenter/values.${{ vars.ENV_SHORTHAND }}.yaml \
            --set appName=${APP_NAME}-${{ vars.ENV_SHORTHAND }} \
            --set nodeRole=$NODE_ROLE_NAME \
            --namespace karpenter

      - name: eks load balancer controller iam policy
        id: iam-policy
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          POLICY_NAME="AWSLoadBalancerControllerIAMPolicy"
          POLICY_ARN="arn:aws:iam::${ACCOUNT_ID}:policy/${POLICY_NAME}"
          
          if aws iam get-policy --policy-arn "$POLICY_ARN" 2>/dev/null; then
            echo "IAM Policy already exists"
          else
            echo "Creating IAM Policy..."
            curl -fsSL -o iam_policy.json \
              https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v${{ env.LB_CONTROLLER_VERSION }}/docs/install/iam_policy.json
            aws iam create-policy --policy-name "$POLICY_NAME" --policy-document file://iam_policy.json
          fi
          
          echo "POLICY_ARN=$POLICY_ARN" >> $GITHUB_ENV
      
      - name: eks load balancer controller service account + role
        run: |
          eksctl create iamserviceaccount \
            --cluster=$CLUSTER_NAME \
            --region=${{ env.AWS_REGION }} \
            --namespace=kube-system \
            --name=aws-load-balancer-controller \
            --attach-policy-arn=$POLICY_ARN \
            --override-existing-serviceaccounts \
            --approve
      
      - name: eks load balancer controller helm chart
        run: |
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update
          
          helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
            --namespace kube-system \
            --set clusterName=$CLUSTER_NAME \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=${{ env.AWS_REGION }} \
            --set vpcId=$VPC_ID \
            --wait

      - name: deploy app infra
        run: |
          echo "executing app helm..."
          helm upgrade --install app ./infra/helm/app \
            -f ./infra/helm/app/values.${{ vars.ENV_SHORTHAND }}.yaml \
            --set frontend.ingress.certificateArn=$CERTIFICATE_ARN