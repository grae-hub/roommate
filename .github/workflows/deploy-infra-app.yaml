name: deploy app infra

on:
  workflow_dispatch:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      cluster_name:
        required: true
        type: string
      certificate_arn:
        required: true
        type: string
      user_pool_arn:
        required: true
        type: string
      user_pool_client_id:
        required: true
        type: string
      user_pool_domain_prefix:
        required: true
        type: string

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}

    env:
      AWS_REGION: ap-southeast-2
      APP_NAME: roommate

    steps:
      - name: checkout
        uses: actions/checkout@v4

      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE }}
          aws-region: ${{ env.AWS_REGION }}

      - name: login to docker hub
        uses: docker/login-action@v3
        with:
          username: grae888
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: update kubeconfig
        run: |
          echo "configuring kubectl connection to cluster..."
          aws eks update-kubeconfig --name ${{ inputs.cluster_name }} --region ${AWS_REGION}
  
      - name: deploy app infra
        run: |
          echo "executing app helm..."
          helm upgrade --install app ./infra/helm/app \
            -f ./infra/helm/app/values.${{ vars.ENV_SHORTHAND }}.yaml \
            --set frontend.ingress.certificateArn=${{ inputs.certificate_arn }} \
            --set frontend.ingress.cognito.userPoolArn=${{ inputs.user_pool_arn }} \
            --set frontend.ingress.cognito.userPoolClientId=${{ inputs.user_pool_client_id }} \
            --set frontend.ingress.cognito.userPoolDomainPrefix=${{ inputs.user_pool_domain_prefix }} \
  
      - name: get ingress alb hostname
        run: |
          INGRESS_NAME=${{ env.APP_NAME }}-ingress
  
          # wait for alb to be provisioned (up to 5 minutes)
          for i in {1..30}; do
            ALB_HOSTNAME=$(kubectl get ingress $INGRESS_NAME \
              -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
              
            if [ -n "${ALB_HOSTNAME}" ]; then
              echo "alb hostname: ${ALB_HOSTNAME}"
              echo "ALB_HOSTNAME=${ALB_HOSTNAME}" >> $GITHUB_ENV
              break
            fi
              
            echo "waiting for alb to be provisioned... ($i/30)"
            sleep 10
          done
  
          if [ -z "${ALB_HOSTNAME}" ]; then
            echo "alb not found"
            exit 1
          fi
  
      - name: get ingress alb hosted zone
        run: |
          ALB_HOSTED_ZONE_ID=$(aws elbv2 describe-load-balancers \
            --region ${{ env.AWS_REGION }} \
            --query "LoadBalancers[?DNSName=='${ALB_HOSTNAME}'].CanonicalHostedZoneId" \
            --output text)
  
          echo "got hosted zone id"
          echo "ALB_HOSTED_ZONE_ID=${ALB_HOSTED_ZONE_ID}" >> $GITHUB_ENV
  
      - name: create ingress alb record
        run: |
          cat > change_batch.json << EOF
          {
            "Changes": [
              {
                "Action": "UPSERT",
                "ResourceRecordSet": {
                  "Name": "${{ vars.DOMAIN_NAME }}",
                  "Type": "A",
                  "AliasTarget": {
                    "HostedZoneId": "${ALB_HOSTED_ZONE_ID}",
                    "DNSName": "${ALB_HOSTNAME}",
                    "EvaluateTargetHealth": true
                  }
                }
              }
            ]
          }
          EOF
  
          echo "creating dns record..."
          cat change_batch.json
  
          aws route53 change-resource-record-sets \
            --hosted-zone-id ${{ secrets.HOSTED_ZONE_ID }} \
            --change-batch file://change_batch.json
  
          echo "dns record created ${{ vars.DOMAIN_NAME }} -> ${ALB_HOSTNAME}"